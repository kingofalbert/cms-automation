#!/usr/bin/env python3
"""æ¸¬è©¦æ ¡å°æ±ºç­–æœå‹™

æ¸¬è©¦ T7.2 ProofreadingDecisionService çš„å®Œæ•´åŠŸèƒ½ã€‚
"""

import asyncio
import sys
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from src.config.database import get_db_config
from src.config.logging import get_logger
from src.models.article import Article
from src.models.proofreading import DecisionType, ProofreadingDecision, ProofreadingHistory
from src.services.proofreading_decision import (
    DateRange,
    DecisionInput,
    DecisionPatterns,
    ProofreadingDecisionService,
    get_decision_service,
)

logger = get_logger(__name__)


async def create_test_data(session: AsyncSession) -> dict:
    """å‰µå»ºæ¸¬è©¦æ•¸æ“š"""
    print("\nğŸ“ å‰µå»ºæ¸¬è©¦æ•¸æ“š...")

    # 1. å‰µå»ºæ¸¬è©¦æ–‡ç« 
    article = Article(
        title="T7.2 æ¸¬è©¦æ–‡ç« ",
        body="é€™æ˜¯ä¸€ç¯‡ç”¨æ–¼æ¸¬è©¦æ ¡å°æ±ºç­–æœå‹™çš„æ–‡ç« ã€‚æ–‡ç« åŒ…å«äº†å„ç¨®éœ€è¦æ ¡å°çš„å…§å®¹ï¼Œä¾‹å¦‚éŒ¯åˆ¥å­—ã€èªæ³•éŒ¯èª¤ã€æ¨™é»ç¬¦è™Ÿå•é¡Œç­‰ã€‚é€™æ¨£æˆ‘å€‘å¯ä»¥æ¸¬è©¦æ±ºç­–æœå‹™çš„å„ç¨®åŠŸèƒ½ã€‚",
        status="draft"
    )
    session.add(article)
    await session.commit()
    print(f"  âœ… å‰µå»ºæ–‡ç« : ID={article.id}, Title={article.title}")

    # 2. å‰µå»ºæ ¡å°æ­·å²
    proofreading_history = ProofreadingHistory(
        article_id=article.id,
        original_content=article.body,
        corrected_content=article.body.replace("éŒ¯åˆ¥å­—", "éŒ¯èª¤å­—"),
        suggestions=[
            {
                "id": "sug_001",
                "type": "spelling",
                "original": "éŒ¯åˆ¥å­—",
                "suggested": "éŒ¯èª¤å­—",
                "confidence": 0.9,
                "context_before": "å„ç¨®éœ€è¦æ ¡å°çš„å…§å®¹ï¼Œä¾‹å¦‚",
                "context_after": "ã€èªæ³•éŒ¯èª¤ã€æ¨™é»ç¬¦è™Ÿå•é¡Œ"
            },
            {
                "id": "sug_002",
                "type": "grammar",
                "original": "é€™æ¨£æˆ‘å€‘å¯ä»¥",
                "suggested": "é€™æ¨£ï¼Œæˆ‘å€‘å¯ä»¥",
                "confidence": 0.85,
                "context_before": "æ¨™é»ç¬¦è™Ÿå•é¡Œç­‰ã€‚",
                "context_after": "æ¸¬è©¦æ±ºç­–æœå‹™çš„å„ç¨®åŠŸèƒ½"
            },
            {
                "id": "sug_003",
                "type": "punctuation",
                "original": "åŠŸèƒ½ã€‚",
                "suggested": "åŠŸèƒ½ï¼",
                "confidence": 0.7,
                "context_before": "æ¸¬è©¦æ±ºç­–æœå‹™çš„å„ç¨®",
                "context_after": ""
            },
            {
                "id": "sug_004",
                "type": "style",
                "original": "æ–‡ç« åŒ…å«äº†",
                "suggested": "æ–‡ç« å«æœ‰",
                "confidence": 0.6,
                "context_before": "æ¸¬è©¦æ ¡å°æ±ºç­–æœå‹™çš„æ–‡ç« ã€‚",
                "context_after": "å„ç¨®éœ€è¦æ ¡å°çš„å…§å®¹"
            },
            {
                "id": "sug_005",
                "type": "vocabulary",
                "original": "ä¾‹å¦‚",
                "suggested": "æ¯”å¦‚",
                "confidence": 0.75,
                "context_before": "å„ç¨®éœ€è¦æ ¡å°çš„å…§å®¹ï¼Œ",
                "context_after": "éŒ¯åˆ¥å­—ã€èªæ³•éŒ¯èª¤"
            }
        ],
        changes_made=1,
        ai_provider="test_provider",
        processing_time_ms=500,
        quality_score=0.85
    )
    session.add(proofreading_history)
    await session.commit()
    print(f"  âœ… å‰µå»ºæ ¡å°æ­·å²: ID={proofreading_history.id}, å»ºè­°æ•¸={len(proofreading_history.suggestions)}")

    return {
        "article": article,
        "proofreading_history": proofreading_history
    }


async def test_decision_recording(
    service: ProofreadingDecisionService,
    session: AsyncSession,
    test_data: dict
) -> list[ProofreadingDecision]:
    """æ¸¬è©¦æ±ºç­–è¨˜éŒ„åŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦ 1: æ±ºç­–è¨˜éŒ„")
    print("-" * 40)

    article = test_data["article"]
    history = test_data["proofreading_history"]

    decisions_made = []

    # 1. æ¥å—ç¬¬ä¸€å€‹å»ºè­°ï¼ˆæ‹¼å¯«ï¼‰
    print("\n1ï¸âƒ£ è¨˜éŒ„æ¥å—æ±ºç­–...")
    decision1 = await service.record_decision(
        session=session,
        article_id=article.id,
        proofreading_history_id=history.id,
        suggestion_id="sug_001",
        decision=DecisionType.ACCEPT,
        decision_reason="æ‹¼å¯«éŒ¯èª¤ç¢ºå¯¦éœ€è¦ä¿®æ­£",
        tags=["spelling", "accepted"]
    )
    decisions_made.append(decision1)
    print(f"  âœ… æ±ºç­–è¨˜éŒ„: {decision1.suggestion_id} -> {decision1.decision}")

    # 2. æ‹’çµ•ç¬¬äºŒå€‹å»ºè­°ï¼ˆèªæ³•ï¼‰
    print("\n2ï¸âƒ£ è¨˜éŒ„æ‹’çµ•æ±ºç­–...")
    decision2 = await service.record_decision(
        session=session,
        article_id=article.id,
        proofreading_history_id=history.id,
        suggestion_id="sug_002",
        decision=DecisionType.REJECT,
        decision_reason="åŸæ–‡èªæ³•æ²’æœ‰å•é¡Œ",
        tags=["grammar", "rejected"]
    )
    decisions_made.append(decision2)
    print(f"  âœ… æ±ºç­–è¨˜éŒ„: {decision2.suggestion_id} -> {decision2.decision}")

    # 3. ä¿®æ”¹ç¬¬ä¸‰å€‹å»ºè­°ï¼ˆæ¨™é»ï¼‰
    print("\n3ï¸âƒ£ è¨˜éŒ„ä¿®æ”¹æ±ºç­–...")
    decision3 = await service.record_decision(
        session=session,
        article_id=article.id,
        proofreading_history_id=history.id,
        suggestion_id="sug_003",
        decision=DecisionType.MODIFY,
        custom_correction="åŠŸèƒ½ã€‚",  # ä¿æŒåŸæ¨£
        decision_reason="ä¿æŒå¥è™Ÿï¼Œä¸éœ€è¦æ„Ÿå˜†è™Ÿ",
        tags=["punctuation", "modified"]
    )
    decisions_made.append(decision3)
    print(f"  âœ… æ±ºç­–è¨˜éŒ„: {decision3.suggestion_id} -> {decision3.decision} (è‡ªå®šç¾©: {decision3.custom_correction})")

    # 4. æ¸¬è©¦æ‰¹é‡è¨˜éŒ„
    print("\n4ï¸âƒ£ æ‰¹é‡è¨˜éŒ„æ±ºç­–...")
    batch_decisions = [
        DecisionInput(
            suggestion_id="sug_004",
            decision=DecisionType.ACCEPT,
            reason="é¢¨æ ¼æ”¹é€²åˆç†",
            tags=["style"]
        ),
        DecisionInput(
            suggestion_id="sug_005",
            decision=DecisionType.REJECT,
            reason="ä¿æŒåŸè©å½™",
            tags=["vocabulary"]
        )
    ]

    batch_results = await service.record_batch_decisions(
        session=session,
        article_id=article.id,
        proofreading_history_id=history.id,
        decisions=batch_decisions
    )
    decisions_made.extend(batch_results)
    print(f"  âœ… æ‰¹é‡è¨˜éŒ„ {len(batch_results)} å€‹æ±ºç­–")

    return decisions_made


async def test_decision_retrieval(
    service: ProofreadingDecisionService,
    session: AsyncSession,
    test_data: dict
):
    """æ¸¬è©¦æ±ºç­–æŸ¥è©¢åŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦ 2: æ±ºç­–æŸ¥è©¢")
    print("-" * 40)

    article = test_data["article"]

    # 1. æŸ¥è©¢æ–‡ç« çš„æ‰€æœ‰æ±ºç­–
    print("\n1ï¸âƒ£ æŸ¥è©¢æ–‡ç« æ±ºç­–...")
    decisions = await service.get_article_decisions(
        session=session,
        article_id=article.id,
        include_history=True
    )

    print(f"  æ‰¾åˆ° {len(decisions)} å€‹æ±ºç­–:")
    for d in decisions:
        print(f"    - {d.suggestion_id}: {d.decision} ({d.suggestion_type})")

    # 2. æŸ¥è©¢æ±ºç­–æ­·å²
    print("\n2ï¸âƒ£ æŸ¥è©¢æ±ºç­–æ­·å²...")
    history = await service.get_user_decision_history(
        session=session,
        limit=10,
        offset=0
    )

    print(f"  æ‰¾åˆ° {len(history)} æ¢æ­·å²è¨˜éŒ„")

    # 3. æŸ¥è©¢ç‰¹å®šæ™‚é–“ç¯„åœçš„æ±ºç­–
    print("\n3ï¸âƒ£ æŸ¥è©¢ä»Šæ—¥æ±ºç­–...")
    today = datetime.utcnow()
    time_range = DateRange(
        start_date=today.replace(hour=0, minute=0, second=0),
        end_date=today + timedelta(days=1)
    )

    today_decisions = await service.get_user_decision_history(
        session=session,
        time_range=time_range
    )

    print(f"  ä»Šæ—¥æ±ºç­–æ•¸: {len(today_decisions)}")


async def test_pattern_analysis(
    service: ProofreadingDecisionService,
    session: AsyncSession
):
    """æ¸¬è©¦æ¨¡å¼åˆ†æåŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦ 3: æ¨¡å¼åˆ†æ")
    print("-" * 40)

    # 1. åˆ†ææ±ºç­–æ¨¡å¼
    print("\n1ï¸âƒ£ åˆ†ææ±ºç­–æ¨¡å¼...")
    patterns = await service.analyze_decision_patterns(
        session=session,
        min_occurrences=1  # æ¸¬è©¦ç’°å¢ƒé™ä½é–¾å€¼
    )

    print(f"  å¸¸æ¥å—çš„æ¨¡å¼: {len(patterns.common_acceptances)}")
    for pattern in patterns.common_acceptances:
        print(f"    - {pattern.pattern_type}: {pattern.rate:.2%} (n={pattern.frequency})")

    print(f"  å¸¸æ‹’çµ•çš„æ¨¡å¼: {len(patterns.common_rejections)}")
    for pattern in patterns.common_rejections:
        print(f"    - {pattern.pattern_type}: {pattern.rate:.2%} (n={pattern.frequency})")

    print(f"  è‡ªå®šç¾©ä¿®æ­£: {len(patterns.custom_corrections)}")
    for pattern in patterns.custom_corrections:
        print(f"    - {pattern.original_pattern} â†’ {pattern.correction_pattern}")

    # 2. æå–ç”¨æˆ¶åå¥½
    print("\n2ï¸âƒ£ æå–ç”¨æˆ¶åå¥½...")
    preferences = await service.extract_user_preferences(
        session=session,
        min_decisions=1  # æ¸¬è©¦ç’°å¢ƒé™ä½é–¾å€¼
    )

    print(f"  ç½®ä¿¡åº¦: {preferences.confidence_level:.2%}")
    print(f"  é¢¨æ ¼åå¥½: {preferences.style_preferences}")
    print(f"  è©å½™åå¥½: {len(preferences.vocabulary_preferences)} å€‹è©")

    return patterns


async def test_rule_generation(
    service: ProofreadingDecisionService,
    session: AsyncSession,
    patterns: DecisionPatterns
):
    """æ¸¬è©¦è¦å‰‡ç”ŸæˆåŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦ 4: è¦å‰‡ç”Ÿæˆ")
    print("-" * 40)

    # 1. ç”Ÿæˆå­¸ç¿’è¦å‰‡
    print("\n1ï¸âƒ£ ç”Ÿæˆå­¸ç¿’è¦å‰‡...")
    rules = await service.generate_learning_rules(
        session=session,
        patterns=patterns,
        confidence_threshold=0.5  # æ¸¬è©¦ç’°å¢ƒé™ä½é–¾å€¼
    )

    print(f"  ç”Ÿæˆ {len(rules)} æ¢è¦å‰‡:")
    for rule in rules:
        print(f"    - {rule.rule_id}: {rule.rule_type} (ç½®ä¿¡åº¦: {rule.confidence:.2f})")
        if rule.pattern:
            print(f"      æ¨¡å¼: {rule.pattern}")
        if rule.replacement:
            print(f"      æ›¿æ›: {rule.replacement}")

    # 2. æ‡‰ç”¨è¦å‰‡åˆ°æ–°å…§å®¹
    if rules:
        print("\n2ï¸âƒ£ æ‡‰ç”¨è¦å‰‡åˆ°æ–°å…§å®¹...")
        test_content = "é€™æ˜¯æ¸¬è©¦å…§å®¹ï¼ŒåŒ…å«éŒ¯åˆ¥å­—å’Œå…¶ä»–å•é¡Œã€‚"

        modified, applications = await service.apply_learning_rules(
            content=test_content,
            rules=rules
        )

        print(f"  åŸå§‹: {test_content}")
        print(f"  ä¿®æ”¹: {modified}")
        print(f"  æ‡‰ç”¨ {len(applications)} æ¢è¦å‰‡")

        for app in applications:
            print(f"    - {app.rule_id}: {app.original_text} â†’ {app.modified_text}")

    return rules


async def test_feedback_aggregation(
    service: ProofreadingDecisionService,
    session: AsyncSession
):
    """æ¸¬è©¦åé¥‹èšåˆåŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦ 5: åé¥‹èšåˆ")
    print("-" * 40)

    # 1. æ—¥åº¦èšåˆ
    print("\n1ï¸âƒ£ æ—¥åº¦åé¥‹èšåˆ...")
    daily_feedback = await service.aggregate_feedback_data(
        session=session,
        aggregation_period="daily"
    )

    print(f"  ç¸½æ±ºç­–æ•¸: {daily_feedback.total_decisions}")
    print(f"  æ¥å—ç‡: {daily_feedback.acceptance_rate:.2%}")
    print(f"  æ‹’çµ•ç‡: {daily_feedback.rejection_rate:.2%}")
    print(f"  ä¿®æ”¹ç‡: {daily_feedback.modification_rate:.2%}")
    print(f"  å»ºè­°é¡å‹åˆ†å¸ƒ: {daily_feedback.suggestion_type_distribution}")

    # 2. æº–å‚™èª¿å„ªæ•¸æ“šé›†
    print("\n2ï¸âƒ£ æº–å‚™èª¿å„ªæ•¸æ“šé›†...")
    dataset = await service.prepare_tuning_dataset(
        session=session,
        min_examples=5,  # æ¸¬è©¦ç’°å¢ƒé™ä½é–¾å€¼
        balance_dataset=True
    )

    print(f"  æ­£ä¾‹: {len(dataset.positive_examples)}")
    print(f"  è² ä¾‹: {len(dataset.negative_examples)}")
    print(f"  è‡ªå®šç¾©ä¾‹: {len(dataset.custom_examples)}")
    print(f"  å…ƒæ•¸æ“š: {dataset.metadata}")

    return daily_feedback


async def test_quality_evaluation(
    service: ProofreadingDecisionService,
    session: AsyncSession
):
    """æ¸¬è©¦è³ªé‡è©•ä¼°åŠŸèƒ½"""
    print("\nğŸ§ª æ¸¬è©¦ 6: è³ªé‡è©•ä¼°")
    print("-" * 40)

    # 1. è©•ä¼°å»ºè­°è³ªé‡
    print("\n1ï¸âƒ£ è©•ä¼°å»ºè­°è³ªé‡...")
    quality = await service.evaluate_suggestion_quality(
        session=session
    )

    print(f"  æº–ç¢ºç‡: {quality.accuracy:.2%}")
    print(f"  ç›¸é—œæ€§: {quality.relevance:.2%}")
    print(f"  æœ‰ç”¨æ€§: {quality.usefulness:.2%}")
    print(f"  è¶¨å‹¢: {quality.trend}")
    print(f"  è©³æƒ…: {quality.details}")

    # 2. è­˜åˆ¥æ”¹é€²é ˜åŸŸ
    print("\n2ï¸âƒ£ è­˜åˆ¥æ”¹é€²é ˜åŸŸ...")
    improvements = await service.identify_improvement_areas(
        session=session,
        quality_metrics=quality,
        target_accuracy=0.85
    )

    print(f"  éœ€æ”¹é€²é ˜åŸŸ: {len(improvements)}")
    for area in improvements:
        print(f"    - {area.area_name} ({area.priority})")
        print(f"      ç•¶å‰: {area.current_performance:.2%}")
        print(f"      ç›®æ¨™: {area.target_performance:.2%}")
        print(f"      å»ºè­°: {', '.join(area.suggestions[:2])}")

    return quality


async def create_more_test_decisions(
    service: ProofreadingDecisionService,
    session: AsyncSession
):
    """å‰µå»ºæ›´å¤šæ¸¬è©¦æ±ºç­–æ•¸æ“šä»¥ä¾¿æ›´å¥½åœ°æ¸¬è©¦æ¨¡å¼åˆ†æ"""
    print("\nğŸ“ å‰µå»ºé¡å¤–æ¸¬è©¦æ•¸æ“š...")

    # å‰µå»ºå¤šç¯‡æ–‡ç« å’Œæ±ºç­–ä»¥å½¢æˆæ¨¡å¼
    for i in range(5):
        # å‰µå»ºæ–‡ç« 
        article = Article(
            title=f"æ¸¬è©¦æ–‡ç«  {i+2}",
            body=f"é€™æ˜¯ç¬¬ {i+2} ç¯‡æ¸¬è©¦æ–‡ç« çš„å…§å®¹ã€‚",
            status="draft"
        )
        session.add(article)
        await session.commit()

        # å‰µå»ºæ ¡å°æ­·å²
        history = ProofreadingHistory(
            article_id=article.id,
            original_content=article.body,
            corrected_content=article.body,
            suggestions=[
                {
                    "id": f"art{i+2}_sug1",
                    "type": "spelling",
                    "original": "æ¸¬è©¦",
                    "suggested": "æ¸¬é©—",
                    "confidence": 0.9
                },
                {
                    "id": f"art{i+2}_sug2",
                    "type": "grammar",
                    "original": "å…§å®¹",
                    "suggested": "å…§å®¹ã€‚",
                    "confidence": 0.8
                }
            ],
            changes_made=0,
            ai_provider="test_provider",
            processing_time_ms=300,
            quality_score=0.8
        )
        session.add(history)
        await session.commit()

        # å‰µå»ºæ±ºç­–ï¼ˆå½¢æˆæ¨¡å¼ï¼‰
        # ç¸½æ˜¯æ¥å—æ‹¼å¯«å»ºè­°
        await service.record_decision(
            session=session,
            article_id=article.id,
            proofreading_history_id=history.id,
            suggestion_id=f"art{i+2}_sug1",
            decision=DecisionType.ACCEPT,
            decision_reason="æ‹¼å¯«ä¿®æ­£",
            tags=["spelling"]
        )

        # ç¸½æ˜¯æ‹’çµ•èªæ³•å»ºè­°
        await service.record_decision(
            session=session,
            article_id=article.id,
            proofreading_history_id=history.id,
            suggestion_id=f"art{i+2}_sug2",
            decision=DecisionType.REJECT,
            decision_reason="èªæ³•æ­£ç¢º",
            tags=["grammar"]
        )

    print("  âœ… å‰µå»ºäº† 5 ç¯‡é¡å¤–æ–‡ç« å’Œ 10 å€‹æ±ºç­–")


async def cleanup_test_data(session: AsyncSession):
    """æ¸…ç†æ¸¬è©¦æ•¸æ“š"""
    print("\nğŸ§¹ æ¸…ç†æ¸¬è©¦æ•¸æ“š...")

    # åˆªé™¤æ¸¬è©¦å‰µå»ºçš„æ•¸æ“š
    await session.execute(text(
        "DELETE FROM proofreading_decisions WHERE article_id IN (SELECT id FROM articles WHERE title LIKE 'T7.2 æ¸¬è©¦æ–‡ç« %' OR title LIKE 'æ¸¬è©¦æ–‡ç« %')"
    ))
    await session.execute(text(
        "DELETE FROM proofreading_history WHERE article_id IN (SELECT id FROM articles WHERE title LIKE 'T7.2 æ¸¬è©¦æ–‡ç« %' OR title LIKE 'æ¸¬è©¦æ–‡ç« %')"
    ))
    await session.execute(text(
        "DELETE FROM articles WHERE title LIKE 'T7.2 æ¸¬è©¦æ–‡ç« %' OR title LIKE 'æ¸¬è©¦æ–‡ç« %'"
    ))

    await session.commit()
    print("  âœ… æ¸¬è©¦æ•¸æ“šå·²æ¸…ç†")


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("=" * 60)
    print("ğŸš€ T7.2 æ ¡å°æ±ºç­–æœå‹™æ¸¬è©¦")
    print("=" * 60)

    # ç²å–æœå‹™å¯¦ä¾‹
    service = get_decision_service()
    db_config = get_db_config()

    try:
        async with db_config.session() as session:
            # æ¸…ç†ä¹‹å‰çš„æ¸¬è©¦æ•¸æ“š
            await cleanup_test_data(session)

            # å‰µå»ºæ¸¬è©¦æ•¸æ“š
            test_data = await create_test_data(session)

            # åŸ·è¡Œæ¸¬è©¦

            # 1. æ¸¬è©¦æ±ºç­–è¨˜éŒ„
            decisions = await test_decision_recording(service, session, test_data)

            # 2. æ¸¬è©¦æ±ºç­–æŸ¥è©¢
            await test_decision_retrieval(service, session, test_data)

            # å‰µå»ºæ›´å¤šæ¸¬è©¦æ•¸æ“šä»¥å½¢æˆæ¨¡å¼
            await create_more_test_decisions(service, session)

            # 3. æ¸¬è©¦æ¨¡å¼åˆ†æ
            patterns = await test_pattern_analysis(service, session)

            # 4. æ¸¬è©¦è¦å‰‡ç”Ÿæˆ
            rules = await test_rule_generation(service, session, patterns)

            # 5. æ¸¬è©¦åé¥‹èšåˆ
            feedback = await test_feedback_aggregation(service, session)

            # 6. æ¸¬è©¦è³ªé‡è©•ä¼°
            quality = await test_quality_evaluation(service, session)

            print("\n" + "=" * 60)
            print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
            print("=" * 60)

            print("\nğŸ“Š æ¸¬è©¦ç¸½çµ:")
            print(f"  â€¢ è¨˜éŒ„æ±ºç­–: {len(decisions)} å€‹")
            print(f"  â€¢ è­˜åˆ¥æ¨¡å¼: {len(patterns.common_acceptances) + len(patterns.common_rejections)} å€‹")
            print(f"  â€¢ ç”Ÿæˆè¦å‰‡: {len(rules) if 'rules' in locals() else 0} æ¢")
            print(f"  â€¢ èšåˆæ•¸æ“š: {feedback.total_decisions} å€‹æ±ºç­–")
            print(f"  â€¢ è³ªé‡è©•ä¼°: æº–ç¢ºç‡ {quality.accuracy:.2%}")

            # æ¸…ç†æ¸¬è©¦æ•¸æ“š
            await cleanup_test_data(session)

    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
