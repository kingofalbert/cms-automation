"""Unified AI optimization service for Phase 7.

This service generates all AI optimization suggestions (title + SEO + FAQ)
in a single API call to save 40-60% cost and 30-40% time.

Cost comparison:
- Original (2 calls): ~$0.10-0.13 per article, 30-40s
- Unified (1 call): ~$0.06-0.08 per article, 20-30s
- Savings: 40-60% cost, 30-40% time
"""

import json
import logging
import re
from datetime import datetime
from decimal import Decimal
from typing import Any

from anthropic import AsyncAnthropic
from sqlalchemy.ext.asyncio import AsyncSession

from src.models.article import Article
from src.models.article_faq import ArticleFAQ
from src.models.seo_suggestions import SEOSuggestion
from src.models.title_suggestions import TitleSuggestion

logger = logging.getLogger(__name__)


class UnifiedOptimizationService:
    """ç»Ÿä¸€AIä¼˜åŒ–æœåŠ¡.

    ä¸€æ¬¡æ€§ç”Ÿæˆï¼š
    1. æ ‡é¢˜ä¼˜åŒ–å»ºè®®ï¼ˆ3æ®µå¼ï¼Œ2-3ä¸ªé€‰é¡¹ï¼‰
    2. SEOå…³é”®è¯ï¼ˆfocus/primary/secondaryï¼‰
    3. Meta Descriptionä¼˜åŒ–
    4. Tagsæ¨è
    5. FAQç”Ÿæˆï¼ˆ8-10ä¸ªï¼‰

    ä¼˜åŠ¿ï¼šèŠ‚çœTokenæˆæœ¬40-60%ï¼Œå‡å°‘APIè°ƒç”¨æ¬¡æ•°
    """

    def __init__(self, anthropic_client: AsyncAnthropic, db_session: AsyncSession):
        """Initialize service.

        Args:
            anthropic_client: Async Anthropic API client
            db_session: Async database session
        """
        self.client = anthropic_client
        self.db = db_session
        self.model = "claude-opus-4-5-20251101"
        self.max_tokens = 6000  # Increased for comprehensive response
        self.temperature = 0.35  # Balanced creativity

    async def generate_all_optimizations(
        self,
        article: Article,
        regenerate: bool = False,
    ) -> dict[str, Any]:
        """ä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰ä¼˜åŒ–å»ºè®®.

        Args:
            article: Article object with parsed content
            regenerate: Force regeneration even if suggestions exist

        Returns:
            {
                "title_suggestions": {...},
                "seo_suggestions": {...},
                "faqs": [...],
                "generation_metadata": {
                    "total_cost_usd": 0.07,
                    "total_tokens": 6500,
                    "duration_ms": 25000,
                    "savings_vs_separate": {...}
                }
            }

        Raises:
            ValueError: If article not parsed or prompt building fails
            RuntimeError: If AI API call fails
        """
        logger.info(f"Generating unified optimizations for article {article.id}")

        # Validation
        if not article.body_html and not article.body:
            raise ValueError(f"Article {article.id} has no content to optimize")

        # Check if already generated (unless regenerate=True)
        if not regenerate and article.unified_optimization_generated:
            logger.info(f"Article {article.id} already has optimizations, loading from cache")
            return await self._load_existing_optimizations(article.id)

        # Build unified prompt
        start_time = datetime.now()
        prompt = self._build_unified_prompt(article)

        # Call Claude API
        try:
            logger.info(f"Calling Claude API for article {article.id}")
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                messages=[{"role": "user", "content": prompt}],
            )

            # Track usage
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            total_tokens = input_tokens + output_tokens

            # Calculate cost (Claude Sonnet 4.5 pricing: $3/M input, $15/M output)
            cost_usd = (input_tokens / 1_000_000 * 3.0) + (output_tokens / 1_000_000 * 15.0)

            duration_ms = int((datetime.now() - start_time).total_seconds() * 1000)

            logger.info(
                f"Article {article.id} - Claude response received: "
                f"{total_tokens} tokens, ${cost_usd:.4f}, {duration_ms}ms"
            )

        except Exception as e:
            logger.error(f"Claude API call failed for article {article.id}: {e}")
            raise RuntimeError(f"Failed to generate optimizations: {e}")

        # Parse response
        try:
            result = self._parse_unified_response(response.content[0].text)
        except Exception as e:
            logger.error(f"Failed to parse Claude response for article {article.id}: {e}")
            raise ValueError(f"AI response parsing failed: {e}")

        # Store to database
        try:
            await self._store_optimizations(article.id, result)
        except Exception as e:
            logger.error(f"Failed to store optimizations for article {article.id}: {e}")
            raise RuntimeError(f"Database storage failed: {e}")

        # Update article metadata
        article.unified_optimization_generated = True
        article.unified_optimization_generated_at = datetime.now()
        article.unified_optimization_cost = Decimal(str(cost_usd))
        await self.db.commit()

        # Build response with metadata
        faq_assessment = result.get("faq_assessment", {})
        faq_applicable = faq_assessment.get("is_applicable", True)

        return {
            "title_suggestions": result.get("title_suggestions", {}),
            "seo_suggestions": {
                "seo_keywords": result.get("seo_keywords", {}),
                "meta_description": result.get("meta_description", {}),
                "tags": result.get("tags", {}),
            },
            "faqs": result.get("faqs", []),
            # FAQ v2.2 assessment fields
            "faq_assessment": faq_assessment,
            "faq_applicable": faq_applicable,
            "faq_editorial_notes": result.get("faq_editorial_notes", {}),
            "faq_html": article.faq_html,
            "generation_metadata": {
                "total_cost_usd": round(cost_usd, 4),
                "total_tokens": total_tokens,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "duration_ms": duration_ms,
                "savings_vs_separate": self._calculate_savings(cost_usd, total_tokens, duration_ms),
            },
        }

    def _build_unified_prompt(self, article: Article) -> str:
        """æ„å»ºç»Ÿä¸€ä¼˜åŒ–Prompt.

        åŒ…å«5ä¸ªå­ä»»åŠ¡ï¼š
        1. æ ‡é¢˜ä¼˜åŒ–
        2. SEOå…³é”®è¯
        3. Meta Description
        4. Tagsæ¨è
        5. FAQç”Ÿæˆ
        """
        # Build full title from components
        full_title = self._build_full_title(article)

        # Get content for analysis (prioritize body_html)
        content = article.body_html or article.body or ""
        content_preview = content[:800] if len(content) > 800 else content

        # Build comprehensive prompt
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„SEOä¸“å®¶ã€å†…å®¹è¥é”€é¡¾é—®å’Œæ–‡æ¡ˆä¼˜åŒ–å¸ˆã€‚è¯·ä¸ºä»¥ä¸‹æ–‡ç« æä¾›**å…¨é¢çš„ä¼˜åŒ–å»ºè®®**ã€‚

## ğŸ“‹ æ–‡ç« ä¿¡æ¯

### ç»“æ„åŒ–æ•°æ®ï¼ˆå·²è§£æï¼‰

**æ ‡é¢˜ç»„ä»¶**:
- å‰ç¼€: {article.title_prefix or "ï¼ˆæ— ï¼‰"}
- ä¸»æ ‡é¢˜: {article.title_main or article.title}
- å‰¯æ ‡é¢˜: {article.title_suffix or "ï¼ˆæ— ï¼‰"}
- å®Œæ•´æ ‡é¢˜: {full_title}

**ä½œè€…**:
- ä½œè€…è¡Œ: {article.author_line or "ï¼ˆæ— ï¼‰"}
- ä½œè€…å: {article.author_name or "ï¼ˆæ— ï¼‰"}

**åˆæ­¥SEOæ•°æ®**ï¼ˆä»æ–‡æ¡£æå–ï¼‰:
- Meta Description: {article.meta_description or "ï¼ˆæ— ï¼‰"}
- å…³é”®è¯: {", ".join(article.seo_keywords[:10]) if article.seo_keywords else "ï¼ˆæ— ï¼‰"}
- æ ‡ç­¾: {", ".join(article.tags[:5]) if article.tags else "ï¼ˆæ— ï¼‰"}

**æ­£æ–‡å†…å®¹**ï¼ˆå‰800å­—ç¬¦ï¼‰:
{content_preview}...

---

## ğŸ¯ ä¼˜åŒ–ä»»åŠ¡

è¯·ä¸€æ¬¡æ€§å®Œæˆä»¥ä¸‹**5ä¸ªä¼˜åŒ–ä»»åŠ¡**ï¼š

---

### ä»»åŠ¡1: æ ‡é¢˜ä¼˜åŒ–ï¼ˆ3æ®µå¼ï¼‰ğŸ“

ä¸ºä¸‰æ®µå¼æ ‡é¢˜ç»“æ„ç”Ÿæˆ**2-3ä¸ª**ä¼˜åŒ–å»ºè®®ï¼š

```
å®Œæ•´æ ‡é¢˜ = [å‰ç¼€] | ä¸»æ ‡é¢˜ | [å‰¯æ ‡é¢˜]
```

**è¦æ±‚**:
1. ç”Ÿæˆ2-3ä¸ªä¸åŒé£æ ¼çš„æ ‡é¢˜æ–¹æ¡ˆ
2. å¿…é¡»åŒ…å«è‡³å°‘1ä¸ª**Data-Drivenå‹**ï¼ˆåŒ…å«å…·ä½“æ•°æ®ã€ç™¾åˆ†æ¯”ï¼‰
3. æ¨èåŒ…å«1ä¸ª**Authority-Backedå‹**ï¼ˆæƒå¨èƒŒä¹¦ï¼‰æˆ–**How-Toå‹**ï¼ˆæ“ä½œæŒ‡å—ï¼‰
4. å¯é€‰1ä¸ª**Comprehensive Guideå‹**ï¼ˆå…¨é¢æŒ‡å—ï¼‰æˆ–**Question-Basedå‹**ï¼ˆç–‘é—®å¼•å¯¼ï¼‰

**é•¿åº¦è§„èŒƒ**:
- å‰ç¼€: 2-6å­—ç¬¦ï¼ˆç®€çŸ­æœ‰åŠ›ï¼‰
- ä¸»æ ‡é¢˜: 15-30å­—ç¬¦ï¼ˆæ ¸å¿ƒå†…å®¹ï¼‰
- å‰¯æ ‡é¢˜: 4-12å­—ç¬¦ï¼ˆè¡¥å……ä¿¡æ¯ï¼‰
- å®Œæ•´æ ‡é¢˜: 25-50å­—ç¬¦ï¼ˆæ¨èï¼‰ï¼Œä¸è¶…è¿‡70å­—ç¬¦

**è¾“å‡ºæ ¼å¼**:
```json
"title_suggestions": {{
  "suggested_title_sets": [
    {{
      "id": "option_1",
      "title_prefix": "æ·±åº¦è§£æ",
      "title_main": "äººå·¥æ™ºèƒ½é©æ–°åŒ»ç–—è¯Šæ–­ï¼šå‡†ç¡®ç‡æå‡30%",
      "title_suffix": "æƒå¨æŒ‡å—",
      "full_title": "æ·±åº¦è§£æ | äººå·¥æ™ºèƒ½é©æ–°åŒ»ç–—è¯Šæ–­ï¼šå‡†ç¡®ç‡æå‡30% | æƒå¨æŒ‡å—",
      "score": 95,
      "strengths": ["åŒ…å«å…·ä½“æ•°æ®ï¼ˆ30%ï¼‰å¢å¼ºå¯ä¿¡åº¦", "ä½¿ç”¨åŠ¨ä½œè¯"é©æ–°"å¢å¼ºå¸å¼•åŠ›"],
      "type": "data_driven",
      "recommendation": "æœ€ä½³é€‰é¡¹ï¼Œå¹³è¡¡æ•°æ®ä¸å¸å¼•åŠ›",
      "character_count": {{"prefix": 4, "main": 22, "suffix": 4, "total": 34}}
    }},
    {{
      "id": "option_2",
      "title_prefix": "å®ç”¨æŒ‡å—",
      "title_main": "å¦‚ä½•è¿ç”¨AIæŠ€æœ¯æå‡åŒ»ç–—è¯Šæ–­æ•ˆç‡",
      "title_suffix": "ä¸“å®¶è§£è¯»",
      "full_title": "å®ç”¨æŒ‡å— | å¦‚ä½•è¿ç”¨AIæŠ€æœ¯æå‡åŒ»ç–—è¯Šæ–­æ•ˆç‡ | ä¸“å®¶è§£è¯»",
      "score": 88,
      "strengths": ["æ“ä½œæ€§å¼ºï¼Œæä¾›å®ç”¨ä»·å€¼", "ä¸“å®¶èƒŒä¹¦å¢å¼ºæƒå¨æ€§"],
      "type": "how_to",
      "recommendation": "é€‚åˆå¯»æ±‚å®ç”¨å»ºè®®çš„è¯»è€…",
      "character_count": {{"prefix": 4, "main": 18, "suffix": 4, "total": 30}}
    }}
  ],
  "optimization_notes": ["å»ºè®®åœ¨æ ‡é¢˜ä¸­çªå‡ºå…·ä½“æ•°æ®ä»¥å¢å¼ºå¯ä¿¡åº¦", "ä¿æŒæ ‡é¢˜ç®€æ´ï¼Œé¿å…è¶…è¿‡50å­—ç¬¦"],
  "seo_title_suggestions": {{
    "variants": [
      {{
        "id": "seo_variant_1",
        "seo_title": "2024å¹´AIé†«ç™‚å‰µæ–°è¶¨å‹¢",
        "reasoning": "èšç„¦æ ¸å¿ƒé—œéµå­—ã€ŒAIé†«ç™‚ã€å’Œã€Œå‰µæ–°ã€ï¼Œ30å­—å…§ï¼ŒåŒ…å«æ™‚æ•ˆæ€§",
        "keywords_focus": ["AIé†«ç™‚", "å‰µæ–°", "2024"],
        "character_count": 12
      }},
      {{
        "id": "seo_variant_2",
        "seo_title": "AIé†«ç™‚è¨ºæ–·æŠ€è¡“å…¨é¢è§£æ",
        "reasoning": "çªå‡ºã€Œè¨ºæ–·æŠ€è¡“ã€å’Œã€Œå…¨é¢è§£æã€ï¼Œå¸å¼•æ·±åº¦é–±è®€è€…",
        "keywords_focus": ["AIé†«ç™‚", "è¨ºæ–·æŠ€è¡“", "è§£æ"],
        "character_count": 12
      }}
    ],
    "original_seo_title": null,
    "notes": [
      "SEO Title å»ºè­°ä¿æŒåœ¨ 30 å­—ä»¥å…§",
      "åŒ…å«æ ¸å¿ƒé—œéµå­—ä»¥æå‡æœå°‹æ’å",
      "èˆ‡ H1 æ¨™é¡Œä¸»é¡Œä¸€è‡´ä½†æ›´ç²¾ç°¡"
    ]
  }}
}}
```

**æ³¨æ„**: `seo_title_suggestions` æ˜¯æ–°å¢æ¬„ä½ï¼Œç”¨æ–¼ç”Ÿæˆ SEO Titleï¼ˆ`<title>` æ¨™ç±¤ï¼‰å»ºè­°ï¼Œèˆ‡ H1 æ¨™é¡Œåˆ†é–‹ã€‚

**SEO Title vs H1 çš„å€åˆ¥**:
- **H1 æ¨™é¡Œ**: é é¢å…§å®¹çš„ä¸»æ¨™é¡Œï¼Œè¼ƒé•·ï¼ˆ25-50å­—ï¼‰ï¼Œçµ¦ç”¨æˆ¶é–±è®€
- **SEO Title**: æœå°‹å¼•æ“çµæœé¡¯ç¤ºçš„æ¨™é¡Œï¼Œè¼ƒçŸ­ï¼ˆ30å­—å·¦å³ï¼‰ï¼Œçµ¦æœå°‹å¼•æ“çœ‹

**SEO Title è¦æ±‚**:
1. ç”Ÿæˆ 2-3 å€‹ç²¾ç°¡è®Šé«”
2. é•·åº¦: **30å­—å·¦å³**ï¼ˆæœ€å¤š40å­—ï¼‰
3. å¿…é ˆåŒ…å«ä¸»é—œéµè©
4. å¯åŠ å…¥å¹´ä»½ã€æ•¸æ“šç­‰æå‡é»æ“Šç‡
5. èˆ‡ H1 ä¸»é¡Œä¸€è‡´ä½†æ›´ç²¾ç°¡

---

### ä»»åŠ¡2: SEOå…³é”®è¯åˆ†æğŸ”‘

æ·±åº¦åˆ†ææ–‡ç« å†…å®¹ï¼Œç”Ÿæˆä¸‰çº§å…³é”®è¯ä½“ç³»ï¼š

**è¦æ±‚**:
1. **Focus Keyword**ï¼ˆä¸»å…³é”®è¯ï¼‰: 1ä¸ªï¼Œæœç´¢é‡é«˜ã€ç«äº‰é€‚ä¸­ã€ä¸å†…å®¹é«˜åº¦ç›¸å…³
2. **Primary Keywords**ï¼ˆä¸»è¦å…³é”®è¯ï¼‰: 3-5ä¸ªï¼Œè¯­ä¹‰ç›¸å…³
3. **Secondary Keywords**ï¼ˆæ¬¡è¦å…³é”®è¯ï¼‰: 5-10ä¸ªï¼Œé•¿å°¾è¯

**è¾“å‡ºæ ¼å¼**:
```json
"seo_keywords": {{
  "focus_keyword": "äººå·¥æ™ºèƒ½åŒ»ç–—åº”ç”¨",
  "focus_keyword_rationale": "è¯¥è¯æœç´¢é‡é«˜ã€ç«äº‰ä¸­ç­‰ï¼Œä¸æ–‡ç« æ ¸å¿ƒå†…å®¹åŒ¹é…",
  "primary_keywords": ["AIè¯Šæ–­", "åŒ»ç–—å½±åƒåˆ†æ", "æ™ºèƒ½è¾…åŠ©è¯Šæ–­", "æ·±åº¦å­¦ä¹ åŒ»ç–—", "åŒ»ç–—AIæŠ€æœ¯"],
  "secondary_keywords": ["AIæ—©æœŸç­›æŸ¥", "åŒ»ç–—å¤§æ•°æ®åˆ†æ", "æ™ºèƒ½ç—…ç†è¯Šæ–­", "è¿œç¨‹AIè¯Šç–—", "ç²¾å‡†åŒ»ç–—AI", "åŒ»å­¦å½±åƒAIè¯†åˆ«", "ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿ", "AIè¾…åŠ©æ‰‹æœ¯", "æ™ºèƒ½å¥åº·ç®¡ç†", "åŒ»ç–—æœºå™¨å­¦ä¹ "],
  "keyword_difficulty": {{"focus_keyword": 0.65, "average_difficulty": 0.52}},
  "search_volume_estimate": {{"focus_keyword": "5000-10000/æœˆ", "primary_keywords_total": "15000-25000/æœˆ"}}
}}
```

---

### ä»»åŠ¡3: Meta Descriptionä¼˜åŒ–ğŸ“„

åŸºäºæ–‡ç« å†…å®¹ç”Ÿæˆå¸å¼•ç‚¹å‡»çš„Meta Descriptionï¼š

**è¦æ±‚**:
1. é•¿åº¦: 150-160å­—ç¬¦
2. åŒ…å«Focus Keyword
3. å…·æœ‰å¸å¼•ç‚¹å‡»çš„å…ƒç´ ï¼ˆæ•°æ®ã€è¡ŒåŠ¨å·å¬ã€ç‹¬ç‰¹ä»·å€¼ï¼‰
4. å¦‚æœåŸæ–‡å·²æœ‰Meta Descriptionï¼Œè¿›è¡Œä¼˜åŒ–æ”¹è¿›

**è¾“å‡ºæ ¼å¼**:
```json
"meta_description": {{
  "original_meta_description": "æœ¬æ–‡ä»‹ç»AIåœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ã€‚",
  "suggested_meta_description": "æ·±å…¥è§£æAIå¦‚ä½•é©æ–°åŒ»ç–—è¯Šæ–­ï¼šä»å½±åƒåˆ†æåˆ°æ—©æœŸç­›æŸ¥ï¼Œäº†è§£äººå·¥æ™ºèƒ½å¦‚ä½•æå‡è¯Šæ–­å‡†ç¡®ç‡30%ä»¥ä¸Šï¼ŒåŠ©åŠ›ç²¾å‡†åŒ»ç–—å‘å±•ã€‚",
  "meta_description_improvements": [
    "æ·»åŠ å…·ä½“æ•°æ®ï¼ˆ30%ï¼‰å¢å¼ºå¯ä¿¡åº¦",
    "ä½¿ç”¨åŠ¨ä½œè¯"é©æ–°"ã€"æå‡"å¢å¼ºå¸å¼•åŠ›",
    "åŒ…å«ä¸»å…³é”®è¯"AIåŒ»ç–—è¯Šæ–­"",
    "ç¬¦åˆ150-160å­—ç¬¦æœ€ä½³é•¿åº¦"
  ],
  "meta_description_score": 92
}}
```

---

### ä»»åŠ¡4: Tagsæ¨èğŸ·ï¸

åˆ†æå†…å®¹åæ¨èç›¸å…³æ ‡ç­¾ï¼š

**è¦æ±‚**:
1. æ¨è6-8ä¸ªæ ‡ç­¾
2. åŒ…å«é«˜é¢‘æ ‡ç­¾ï¼ˆæµé‡å…¥å£ï¼‰+ ä¸­é¢‘æ ‡ç­¾ï¼ˆç²¾å‡†å®šä½ï¼‰+ é•¿å°¾æ ‡ç­¾ï¼ˆç»†åˆ†æµé‡ï¼‰
3. æ ‡ç­¾ä¸æ–‡ç« å†…å®¹é«˜åº¦ç›¸å…³
4. ä¼˜å…ˆæ¨èå¯èƒ½å·²å­˜åœ¨çš„å¸¸è§æ ‡ç­¾

**è¾“å‡ºæ ¼å¼**:
```json
"tags": {{
  "suggested_tags": [
    {{"tag": "äººå·¥æ™ºèƒ½", "relevance": 0.95, "type": "primary"}},
    {{"tag": "åŒ»ç–—AI", "relevance": 0.92, "type": "primary"}},
    {{"tag": "æ·±åº¦å­¦ä¹ åŒ»ç–—åº”ç”¨", "relevance": 0.78, "type": "secondary"}},
    {{"tag": "AIè¯Šæ–­å·¥å…·", "relevance": 0.85, "type": "trending"}},
    {{"tag": "åŒ»å­¦å½±åƒåˆ†æ", "relevance": 0.82, "type": "primary"}},
    {{"tag": "æ™ºèƒ½åŒ»ç–—", "relevance": 0.88, "type": "primary"}},
    {{"tag": "åŒ»ç–—åˆ›æ–°æŠ€æœ¯", "relevance": 0.75, "type": "secondary"}},
    {{"tag": "ç²¾å‡†åŒ»ç–—", "relevance": 0.80, "type": "secondary"}}
  ],
  "recommended_tag_count": "å»ºè®®ä½¿ç”¨6-8ä¸ªæ ‡ç­¾",
  "tag_strategy": "3ä¸ªé«˜é¢‘æ ‡ç­¾ + 3ä¸ªä¸­é¢‘æ ‡ç­¾ + 2ä¸ªé•¿å°¾æ ‡ç­¾"
}}
```

---

### ä»»å‹™5: FAQç”Ÿæˆï¼ˆAIæœç´¢å„ªåŒ–ç‰ˆ v2.3ï¼‰â“

ä½ æ˜¯ä¸€åè³‡æ·±SEOå°ˆå®¶åŠè³‡è¨Šæ¶æ§‹å¸«ï¼Œç²¾é€šGoogle AI Overviewsã€ChatGPTã€Perplexityç­‰AIæœç´¢å¼•æ“çš„æŠ“å–é‚è¼¯èˆ‡E-E-A-Tè©•æ ¸æ¨™æº–ã€‚

> **é‡è¦èƒŒæ™¯**: æ ¹æ“š2025å¹´è¡Œæ¥­æ•¸æ“šï¼ŒFAQçµæ§‹åŒ–æ•¸æ“šåœ¨AIæœç´¢å¼•æ“ä¸­çš„å¼•ç”¨ç‡æ¥µé«˜ã€‚å¸¶æœ‰FAQ Schemaçš„é é¢åœ¨Google AI Overviewsä¸­å‡ºç¾çš„æ©Ÿç‡æ˜¯ç„¡FAQé é¢çš„**3.2å€**ã€‚AIæœç´¢æµé‡å¹´å¢é•·è¶…é500%ã€‚

#### 5.1 é©é…æ€§è©•ä¼°ï¼ˆåƒ¹å€¼å°å‘åˆ¤æ–·ï¼‰

åˆ†ææ–‡ç« å…§å®¹ï¼Œåˆ¤æ–·æ˜¯å¦èƒ½å¾FAQä¸­ç²å¾—**AIæœç´¢å¯è¦‹æ€§æ”¶ç›Š**ï¼š

**é©åˆå¢åŠ FAQçš„æ–‡ç« é¡å‹**ï¼ˆçµ•å¤§å¤šæ•¸æ–‡ç« éƒ½é©åˆï¼‰:
- å¥åº·é¤Šç”Ÿã€ä¸­é†«ä¿å¥ã€ç‡Ÿé¤Šé£Ÿç™‚ï¼ˆæ ¸å¿ƒå—çœ¾ï¼‰
- ç–¾ç—…é é˜²ã€ç—‡ç‹€èªªæ˜ã€æ²»ç™‚æ–¹æ³•
- æ·±åº¦åˆ†æå ±å°ã€å°ˆé¡Œæ–°èï¼ˆæœ‰ã€Œç‚ºä»€éº¼ã€ã€Œæ€éº¼è¾¦ã€çš„å•é¡Œç©ºé–“ï¼‰
- ç”Ÿæ´»æŠ€å·§ã€æ“ä½œæŒ‡å—ã€ç”¢å“è©•æ¸¬
- ä»»ä½•**è¶…é300å­—ä¸”åŒ…å«å¯æå•å…§å®¹**çš„æ–‡ç« 

**ä¸é©åˆå¢åŠ FAQçš„æƒ…æ³**ï¼ˆæ¥µå°‘æ•¸ä¾‹å¤–ï¼‰:
- ç´”äº‹ä»¶é€šå ±å‹å¿«è¨Šï¼ˆå¦‚ã€ŒæŸåœ°ç™¼ç”Ÿè»Šç¦ã€- ç„¡å»¶ä¼¸å•ç­”ç©ºé–“ï¼‰
- æ¥µçŸ­å…§å®¹ï¼ˆ<300å­—ï¼‰
- ç´”åœ–ç‰‡é›†/å½±ç‰‡é›†ï¼ˆç„¡å¯¦è³ªæ–‡å­—å…§å®¹ï¼‰
- å»£å‘Š/æ¨å»£è»Ÿæ–‡ï¼ˆå¯èƒ½è¢«è¦–ç‚ºèª¤å°ï¼‰

**è¼¸å‡ºæ ¼å¼ï¼ˆé©é…æ€§è©•ä¼°ï¼‰**:
```json
"faq_assessment": {{
  "is_applicable": true,
  "reason": "æœ¬æ–‡å…§å®¹æ·±åº¦è¶³å¤ ï¼Œè®€è€…å¯èƒ½æœ‰å¤šå€‹å»¶ä¼¸ç–‘å•ï¼Œé©åˆå¢åŠ FAQæå‡AIæœç´¢å¯è¦‹æ€§",
  "target_pain_points": ["ç†è§£æ ¸å¿ƒæ¦‚å¿µ", "äº†è§£å¯¦éš›æ‡‰ç”¨", "æ˜ç¢ºæ³¨æ„äº‹é …"]
}}
```

è‹¥ `is_applicable` ç‚º `false`ï¼Œå‰‡ `faqs` é™£åˆ—ç‚ºç©ºã€‚

#### 5.2 FAQæ·±åº¦æ’°å¯«ï¼ˆAIæœç´¢å„ªåŒ–ï¼‰

è¨­è¨ˆ**3-5å€‹**é«˜è³ªé‡å•é¡Œï¼Œéµå¾ªä»¥ä¸‹è¦æ±‚ï¼š

**å•é¡Œè¨­è¨ˆåŸå‰‡ï¼ˆ5W1Hè‡ªç„¶èªè¨€ï¼‰**:
- ä½¿ç”¨è®€è€…çœŸå¯¦æœƒè¼¸å…¥çš„**å£èªåŒ–æå•**ï¼Œè€Œéå°ˆæ¥­è¡“èª
- é‹ç”¨5W1Hæ¡†æ¶ï¼šèª°(Who)ã€ä»€éº¼(What)ã€ä½•æ™‚(When)ã€ä½•åœ°(Where)ã€ç‚ºä½•(Why)ã€å¦‚ä½•(How)
- âœ… å¥½ï¼šã€Œé€™å€‹æ–¹æ³•å¤šä¹…èƒ½è¦‹æ•ˆï¼Ÿã€ã€Œå“ªäº›äººä¸èƒ½ç”¨ï¼Ÿã€
- âŒ å·®ï¼šã€Œç™‚ç¨‹æ™‚é•·ã€ã€Œç¦å¿Œç—‡ã€

**å•é¡Œé¡å‹åˆ†ä½ˆ**ï¼ˆå»ºè­°è¦†è“‹2-3ç¨®ï¼‰:
- **å®šç¾©å‹(what)**: ã€ŒXXæ˜¯ä»€éº¼ï¼Ÿã€ã€ŒXXæœ‰ä»€éº¼ä½œç”¨ï¼Ÿã€
- **æ“ä½œå‹(how)**: ã€Œæ€éº¼åšï¼Ÿã€ã€Œå¦‚ä½•ä½¿ç”¨ï¼Ÿã€
- **æ¯”è¼ƒå‹(vs)**: ã€ŒAå’ŒBæœ‰ä»€éº¼å€åˆ¥ï¼Ÿã€
- **é©ç”¨å‹(who/when)**: ã€Œèª°é©åˆï¼Ÿã€ã€Œä»€éº¼æ™‚å€™ç”¨ï¼Ÿã€
- **åŸå› å‹(why)**: ã€Œç‚ºä»€éº¼æœƒé€™æ¨£ï¼Ÿã€

**ç­”æ¡ˆå¯«ä½œè¦ç¯„ï¼ˆAI Featured Snippetå„ªåŒ–ï¼‰**:

1. **é¦–å¥å®šè«–æ³•**: ç¬¬ä¸€å¥è©±**å¿…é ˆç›´æ¥å›ç­”å•é¡Œ**ï¼Œé€™æ˜¯AIæ‘˜è¦æŠ“å–çš„é—œéµ
   - âœ…ã€Œä¸€èˆ¬å»ºè­°é£¯å¾Œ30åˆ†é˜æœç”¨ã€‚ã€
   - âŒã€Œé—œæ–¼æœç”¨æ™‚é–“ï¼Œéœ€è¦è€ƒæ…®å¤šç¨®å› ç´ ...ã€

2. **è‡ªæ´½å®Œæ•´æ€§**: æ¯å€‹ç­”æ¡ˆå¿…é ˆç¨ç«‹é–‰ç’°
   - åš´ç¦ï¼šã€Œå¦‚å‰æ‰€è¿°ã€ã€Œè¦‹ä¸Šæ–‡ã€ã€Œåƒè€ƒæ­£æ–‡ã€
   - ç¢ºä¿è¢«AIå–®ç¨å¼•ç”¨æ™‚é‚è¼¯å®Œæ•´

3. **å­—æ•¸é»ƒé‡‘å¾‹**: **40-60å­—**ï¼ˆä¸­æ–‡ï¼‰/ 40-80 wordsï¼ˆè‹±æ–‡ï¼‰
   - é€™æ˜¯Featured Snippetå’ŒAI Overviewsçš„æœ€ä½³æŠ“å–é•·åº¦
   - éçŸ­ç¼ºä¹ä¿¡æ¯é‡ï¼Œéé•·è¢«æˆªæ–·

4. **é—œéµè©è‡ªç„¶åµŒå…¥**: å°‡Focus Keywordè‡ªç„¶èå…¥è‡³å°‘1-2å€‹FAQç­”æ¡ˆä¸­

**å¥åº·é¡YMYLåˆè¦ï¼ˆE-E-A-Tå¼·åŒ–ï¼‰**:
- æ˜ç¢ºè²æ˜ã€Œæœ¬è³‡è¨Šåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆé†«ç™‚å»ºè­°ã€
- ç‰¹æ®Šäººç¾¤ï¼ˆå­•å©¦ã€æ…¢æ€§ç—…æ‚£è€…ã€æœè—¥è€…ï¼‰å¿…é ˆæ¨™è¨»å®‰å…¨è­¦ç¤º
- é¿å…çµ•å°åŒ–ï¼šä¸ç”¨ã€Œä¸€å®šã€ã€Œä¿è­‰ã€ã€Œ100%ã€ï¼Œæ”¹ç”¨ã€Œæœ‰åŠ©æ–¼ã€ã€Œå»ºè­°ã€ã€Œé€šå¸¸ã€
- å»ºè­°è«®è©¢å°ˆæ¥­äººå£«çš„èªå¥

**è¼¸å‡ºæ ¼å¼**:
```json
"faqs": [
  {{
    "question": "å“ªäº›äººä¸é©åˆä½¿ç”¨é€™å€‹æ–¹æ³•ï¼Ÿ",
    "answer": "å­•å©¦ã€å“ºä¹³æœŸå©¦å¥³åŠæ­£åœ¨æœç”¨æŠ—å‡è¡€è—¥ç‰©è€…ä¸å»ºè­°ä½¿ç”¨ã€‚æ…¢æ€§ç—…æ‚£è€…æ‡‰å…ˆè«®è©¢é†«å¸«ï¼Œç¢ºèªæ˜¯å¦èˆ‡ç¾æœ‰æ²»ç™‚æ–¹æ¡ˆè¡çªã€‚",
    "question_type": "factual",
    "search_intent": "informational",
    "keywords_covered": ["ç¦å¿Œäººç¾¤", "å­•å©¦", "æ…¢æ€§ç—…"],
    "confidence": 0.92,
    "safety_warning": true
  }},
  {{
    "question": "ä»€éº¼æ™‚å€™åšæ•ˆæœæœ€å¥½ï¼Ÿ",
    "answer": "å»ºè­°åœ¨é£¯å¾Œ30åˆ†é˜é€²è¡Œï¼Œæ­¤æ™‚èº«é«”å¸æ”¶èƒ½åŠ›è¼ƒä½³ã€‚æ—©æ™¨æˆ–å‚æ™šå‡å¯ï¼Œé—œéµæ˜¯ä¿æŒè¦å¾‹ï¼ŒæŒçºŒ2-4é€±å¯è§€å¯Ÿåˆ°æ˜é¡¯è®ŠåŒ–ã€‚",
    "question_type": "how_to",
    "search_intent": "informational",
    "keywords_covered": ["æœ€ä½³æ™‚é–“", "é£¯å¾Œ", "è¦å¾‹"],
    "confidence": 0.88,
    "safety_warning": false
  }},
  {{
    "question": "é€™å€‹æ–¹æ³•æœ‰ç§‘å­¸ä¾æ“šå—ï¼Ÿ",
    "answer": "å¤šé …è‡¨åºŠç ”ç©¶é¡¯ç¤ºå…¶å…·æœ‰ä¸€å®šæ•ˆæœï¼Œä½†å› å€‹äººé«”è³ªå·®ç•°ï¼Œæ•ˆæœå¯èƒ½æœ‰æ‰€ä¸åŒã€‚å¦‚æŒçºŒç„¡æ”¹å–„ï¼Œå»ºè­°è«®è©¢å°ˆæ¥­é†«å¸«è©•ä¼°ã€‚",
    "question_type": "factual",
    "search_intent": "informational",
    "keywords_covered": ["ç§‘å­¸ä¾æ“š", "ç ”ç©¶", "æ•ˆæœ"],
    "confidence": 0.85,
    "safety_warning": false
  }}
],
"faq_editorial_notes": {{
  "longtail_keywords_covered": ["ä½¿ç”¨ç¦å¿Œ", "æœ€ä½³æ™‚é–“", "æ•ˆæœé€±æœŸ"],
  "multimedia_suggestions": ["ç¤ºç¯„åœ–è§£", "æ­¥é©Ÿæµç¨‹åœ–", "å‰å¾Œå°æ¯”"],
  "tone_adjustment_needed": false,
  "disclaimer_required": true,
  "focus_keyword_in_faq": true
}}
```

---

## ğŸ“¤ æœ€çµ‚è¼¸å‡ºæ ¼å¼

è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹JSON Schemaè¼¸å‡ºæ‰€æœ‰5å€‹ä»»å‹™çš„çµæœï¼š

```json
{{
  "title_suggestions": {{
    "suggested_title_sets": [...],
    "optimization_notes": [...],
    "seo_title_suggestions": {{...}}
  }},
  "seo_keywords": {{
    "focus_keyword": "...",
    "primary_keywords": [...],
    "secondary_keywords": [...],
    ...
  }},
  "meta_description": {{
    "suggested_meta_description": "...",
    "meta_description_improvements": [...],
    ...
  }},
  "tags": {{
    "suggested_tags": [...],
    ...
  }},
  "faq_assessment": {{
    "is_applicable": true/false,
    "reason": "èªªæ˜ç‚ºä½•é©åˆ/ä¸é©åˆå¢åŠ FAQ",
    "target_pain_points": ["ç—›é»1", "ç—›é»2"]
  }},
  "faqs": [
    {{"question": "...", "answer": "...", "safety_warning": true/false, ...}},
    // ... 3-5å€‹FAQï¼ˆè‹¥é©ç”¨ï¼‰
  ],
  "faq_editorial_notes": {{
    "longtail_keywords_covered": [...],
    "multimedia_suggestions": [...],
    "tone_adjustment_needed": false,
    "disclaimer_required": true
  }}
}}
```

---

## âš ï¸ é‡è¦æ³¨æ„äº‹é …

1. **å…§å®¹ä¸€è‡´æ€§**: æ¨™é¡Œã€é—œéµè©ã€Metaã€Tagsã€FAQæ‡‰ç›¸äº’å”èª¿ï¼Œä½¿ç”¨çµ±ä¸€çš„æ ¸å¿ƒæ¦‚å¿µ
2. **é—œéµè©è¦†è“‹**: ç¢ºä¿Focus Keywordåœ¨æ¨™é¡Œã€Meta Descriptionã€**è‡³å°‘1å€‹FAQç­”æ¡ˆ**ä¸­éƒ½æœ‰å‡ºç¾
3. **æ•¸æ“šæº–ç¢º**: FAQç­”æ¡ˆå¿…é ˆåŸºæ–¼æ–‡ç« å…§å®¹ï¼Œä¸å¾—æœæ’°æ•¸æ“šæˆ–çµ±è¨ˆæ•¸å­—
4. **é•·åº¦æ§åˆ¶**: åš´æ ¼éµå®ˆFAQç­”æ¡ˆ40-60å­—é™åˆ¶ï¼ˆAIæ‘˜è¦æœ€ä½³æŠ“å–é•·åº¦ï¼‰
5. **é¦–å¥å®šè«–**: FAQç­”æ¡ˆç¬¬ä¸€å¥å¿…é ˆç›´æ¥å›ç­”å•é¡Œï¼Œé€™æ˜¯Featured SnippetæŠ“å–çš„é—œéµ
6. **YMYLåˆè¦**: å¥åº·é¡FAQå¿…é ˆåŒ…å«é©ç•¶çš„å®‰å…¨è­¦ç¤ºå’Œå…è²¬è²æ˜
7. **AIæœç´¢å„ªåŒ–**: çµ•å¤§å¤šæ•¸æ–‡ç« éƒ½æ‡‰ç”ŸæˆFAQä»¥æå‡AIæœç´¢å¯è¦‹æ€§ï¼Œåƒ…æ¥µå°‘æ•¸ä¾‹å¤–ï¼ˆç´”äº‹ä»¶å¿«è¨Š<300å­—ï¼‰è¨­ç½® `is_applicable = false`

---

ç¾åœ¨è«‹å®Œæˆæ‰€æœ‰5å€‹å„ªåŒ–ä»»å‹™ã€‚"""

        return prompt

    def _build_full_title(self, article: Article) -> str:
        """æ„å»ºå®Œæ•´æ ‡é¢˜."""
        parts = []
        if article.title_prefix:
            parts.append(article.title_prefix)

        # Use title_main if available, otherwise fall back to title
        main_title = article.title_main or article.title
        parts.append(main_title)

        if article.title_suffix:
            parts.append(article.title_suffix)

        return " | ".join(parts)

    def _parse_unified_response(self, response_text: str) -> dict[str, Any]:
        """è§£æAIå“åº”.

        æå–ï¼š
        - title_suggestions
        - seo_keywords
        - meta_description
        - tags
        - faqs
        """
        # Try to extract JSON from response
        # Pattern 1: Look for JSON code block
        json_match = re.search(r"```json\s*(\{.*?\})\s*```", response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # Pattern 2: Try to find raw JSON object
            json_match = re.search(r"\{.*\}", response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                raise ValueError("No JSON found in AI response")

        try:
            data = json.loads(json_str)
            logger.info("Successfully parsed AI response JSON")
            return data
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse AI response JSON: {e}")
            logger.debug(f"Response text (first 500 chars): {response_text[:500]}")
            raise ValueError(f"AI response JSON parsing failed: {e}")

    async def _store_optimizations(self, article_id: int, result: dict[str, Any]) -> None:
        """åˆ†åˆ¥å­˜å„²å„ªåŒ–çµæœåˆ°å°æ‡‰çš„è¡¨.

        Args:
            article_id: Article ID
            result: AIç”Ÿæˆçš„å®Œæ•´çµæœ
        """
        logger.info(f"Storing optimizations for article {article_id}")

        # Get article to access original title components
        from sqlalchemy import select

        stmt = select(Article).where(Article.id == article_id)
        db_result = await self.db.execute(stmt)
        article = db_result.scalar_one()

        # 1. å­˜å„²æ¨™é¡Œå»ºè­°åˆ° title_suggestions è¡¨
        title_data = result.get("title_suggestions", {})
        await self._save_title_suggestions(article_id, article, title_data)

        # 2. å­˜å„²SEOå»ºè­°åˆ° seo_suggestions è¡¨
        seo_keywords = result.get("seo_keywords", {})
        meta_desc = result.get("meta_description", {})
        tags_data = result.get("tags", {})

        await self._save_seo_suggestions(article_id, seo_keywords, meta_desc, tags_data)

        # 3. è™•ç†FAQé©é…æ€§è©•ä¼° (v2.2)
        faq_assessment = result.get("faq_assessment", {})
        faq_applicable = faq_assessment.get("is_applicable", True)
        faq_editorial_notes = result.get("faq_editorial_notes", {})

        # å­˜å„²FAQè©•ä¼°åˆ° article
        article.faq_applicable = faq_applicable
        article.faq_assessment = faq_assessment
        article.faq_editorial_notes = faq_editorial_notes

        # 4. å­˜å„²FAQåˆ° article_faqs è¡¨ (åƒ…ç•¶é©ç”¨æ™‚)
        faqs = result.get("faqs", [])
        if faq_applicable and faqs:
            await self._save_faqs(article_id, faqs)
            # ç”ŸæˆFAQ HTMLå€å¡Š
            faq_html = self._generate_faq_html(faqs, faq_editorial_notes)
            article.faq_html = faq_html
            logger.info(f"Generated FAQ HTML for article {article_id}")
        else:
            logger.info(f"FAQ not applicable for article {article_id}: {faq_assessment.get('reason', 'N/A')}")

        await self.db.commit()
        logger.info(f"Successfully stored all optimizations for article {article_id}")

    async def _save_title_suggestions(
        self, article_id: int, article: Article, data: dict
    ) -> None:
        """å­˜å‚¨æ ‡é¢˜å»ºè®®ï¼ˆåŒ…å« H1 å’Œ SEO Titleï¼‰."""
        # Check if already exists
        from sqlalchemy import select

        stmt = select(TitleSuggestion).where(TitleSuggestion.article_id == article_id)
        result = await self.db.execute(stmt)
        existing = result.scalar_one_or_none()

        # Prepare SEO title suggestions data
        seo_title_suggestions = data.get("seo_title_suggestions", {})

        # Update original_seo_title in suggestions if article has extracted seo_title
        if article.seo_title and article.seo_title_extracted:
            if "original_seo_title" not in seo_title_suggestions or not seo_title_suggestions["original_seo_title"]:
                seo_title_suggestions["original_seo_title"] = article.seo_title

        if existing:
            # Update existing
            existing.suggested_title_sets = data.get("suggested_title_sets", [])
            existing.optimization_notes = data.get("optimization_notes", [])
            existing.suggested_seo_titles = seo_title_suggestions if seo_title_suggestions else None
            existing.generated_at = datetime.now()
        else:
            # Create new
            title_suggestion = TitleSuggestion(
                article_id=article_id,
                original_title_prefix=article.title_prefix,
                original_title_main=article.title_main or article.title,
                original_title_suffix=article.title_suffix,
                suggested_title_sets=data.get("suggested_title_sets", []),
                optimization_notes=data.get("optimization_notes", []),
                suggested_seo_titles=seo_title_suggestions if seo_title_suggestions else None,
            )
            self.db.add(title_suggestion)

        logger.info(f"Saved title suggestions (H1 + SEO) for article {article_id}")

    async def _save_seo_suggestions(
        self,
        article_id: int,
        seo_keywords: dict,
        meta_desc: dict,
        tags_data: dict,
    ) -> None:
        """å­˜å‚¨SEOå»ºè®®."""
        from sqlalchemy import select

        stmt = select(SEOSuggestion).where(SEOSuggestion.article_id == article_id)
        result = await self.db.execute(stmt)
        existing = result.scalar_one_or_none()

        if existing:
            # Update existing
            existing.focus_keyword = seo_keywords.get("focus_keyword")
            existing.focus_keyword_rationale = seo_keywords.get("focus_keyword_rationale")
            existing.primary_keywords = seo_keywords.get("primary_keywords", [])
            existing.secondary_keywords = seo_keywords.get("secondary_keywords", [])
            existing.keyword_difficulty = seo_keywords.get("keyword_difficulty")
            existing.search_volume_estimate = seo_keywords.get("search_volume_estimate")
            existing.suggested_meta_description = meta_desc.get("suggested_meta_description")
            existing.meta_description_improvements = meta_desc.get(
                "meta_description_improvements", []
            )
            existing.meta_description_score = meta_desc.get("meta_description_score")
            existing.suggested_tags = tags_data.get("suggested_tags", [])
            existing.tag_strategy = tags_data.get("tag_strategy")
            existing.generated_at = datetime.now()
        else:
            # Create new
            seo_suggestion = SEOSuggestion(
                article_id=article_id,
                focus_keyword=seo_keywords.get("focus_keyword"),
                focus_keyword_rationale=seo_keywords.get("focus_keyword_rationale"),
                primary_keywords=seo_keywords.get("primary_keywords", []),
                secondary_keywords=seo_keywords.get("secondary_keywords", []),
                keyword_difficulty=seo_keywords.get("keyword_difficulty"),
                search_volume_estimate=seo_keywords.get("search_volume_estimate"),
                suggested_meta_description=meta_desc.get("suggested_meta_description"),
                meta_description_improvements=meta_desc.get("meta_description_improvements", []),
                meta_description_score=meta_desc.get("meta_description_score"),
                suggested_tags=tags_data.get("suggested_tags", []),
                tag_strategy=tags_data.get("tag_strategy"),
            )
            self.db.add(seo_suggestion)

        logger.info(f"Saved SEO suggestions for article {article_id}")

    async def _save_faqs(self, article_id: int, faqs: list[dict]) -> None:
        """å­˜å„²FAQ (v2.2)."""
        from sqlalchemy import delete

        # Delete existing FAQs for this article
        stmt = delete(ArticleFAQ).where(ArticleFAQ.article_id == article_id)
        await self.db.execute(stmt)

        # Create new FAQs
        for position, faq_data in enumerate(faqs):
            # Use string values directly (matching varchar columns in database)
            question_type = faq_data.get("question_type", "factual")
            if question_type not in ("factual", "how_to", "comparison", "definition"):
                question_type = "factual"

            search_intent = faq_data.get("search_intent", "informational")
            if search_intent not in ("informational", "navigational", "transactional"):
                search_intent = "informational"

            faq = ArticleFAQ(
                article_id=article_id,
                question=faq_data.get("question", ""),
                answer=faq_data.get("answer", ""),
                question_type=question_type,
                search_intent=search_intent,
                keywords_covered=faq_data.get("keywords_covered", []),
                confidence=faq_data.get("confidence"),
                safety_warning=faq_data.get("safety_warning", False),  # v2.2 YMYL
                position=position,
                status="draft",  # String value instead of enum
            )
            self.db.add(faq)

        logger.info(f"Saved {len(faqs)} FAQs for article {article_id}")

    def _generate_faq_html(self, faqs: list[dict], editorial_notes: dict) -> str:
        """ç”ŸæˆFAQ HTMLå€å¡Š (å¸¸è¦‹å•é¡Œ).

        ç”Ÿæˆå¯è¦‹çš„FAQå€å¡Šï¼Œæ”¾ç½®åœ¨æ–‡ç« æ­£æ–‡åº•éƒ¨ã€‚
        åŒ…å«ï¼š
        1. æ¨™é¡Œã€Œå¸¸è¦‹å•é¡Œã€
        2. å•ç­”åˆ—è¡¨
        3. å…è²¬è²æ˜ï¼ˆå¦‚æœéœ€è¦ï¼‰

        Args:
            faqs: FAQæ•¸æ“šåˆ—è¡¨
            editorial_notes: ç·¨è¼¯å‚™è¨»ï¼ˆåŒ…å«disclaimer_requiredï¼‰

        Returns:
            HTMLå­—ç¬¦ä¸²
        """
        if not faqs:
            return ""

        # é–‹å§‹æ§‹å»ºHTML
        html_parts = [
            '<section class="faq-section" id="faq">',
            '  <h2>å¸¸è¦‹å•é¡Œ</h2>',
            '  <div class="faq-list">',
        ]

        for i, faq in enumerate(faqs, 1):
            question = faq.get("question", "")
            answer = faq.get("answer", "")
            has_warning = faq.get("safety_warning", False)

            html_parts.append(f'    <div class="faq-item" data-index="{i}">')
            html_parts.append(f'      <h3 class="faq-question">Q{i}: {question}</h3>')

            if has_warning:
                html_parts.append(f'      <div class="faq-answer faq-warning">')
                html_parts.append(f'        <span class="warning-icon">âš ï¸</span>')
                html_parts.append(f'        <p>{answer}</p>')
                html_parts.append(f'      </div>')
            else:
                html_parts.append(f'      <div class="faq-answer">')
                html_parts.append(f'        <p>{answer}</p>')
                html_parts.append(f'      </div>')

            html_parts.append('    </div>')

        html_parts.append('  </div>')

        # æ·»åŠ å…è²¬è²æ˜ï¼ˆå¥åº·é¡æ–‡ç« ï¼‰
        if editorial_notes.get("disclaimer_required", False):
            html_parts.append('  <div class="faq-disclaimer">')
            html_parts.append('    <p><em>å…è²¬è²æ˜ï¼šæœ¬æ–‡æä¾›çš„å¥åº·è³‡è¨Šåƒ…ä¾›åƒè€ƒï¼Œä¸èƒ½æ›¿ä»£å°ˆæ¥­é†«ç™‚è¨ºæ–·æˆ–å»ºè­°ã€‚')
            html_parts.append('    å¦‚æœ‰ä»»ä½•å¥åº·å•é¡Œï¼Œè«‹è«®è©¢åˆæ ¼çš„é†«ç™‚å°ˆæ¥­äººå“¡ã€‚</em></p>')
            html_parts.append('  </div>')

        html_parts.append('</section>')

        return '\n'.join(html_parts)

    async def _load_existing_optimizations(self, article_id: int) -> dict[str, Any]:
        """Load existing optimizations from database."""
        from sqlalchemy import select

        # Load article for FAQ assessment fields
        stmt = select(Article).where(Article.id == article_id)
        result = await self.db.execute(stmt)
        article = result.scalar_one_or_none()

        # Load title suggestions
        stmt = select(TitleSuggestion).where(TitleSuggestion.article_id == article_id)
        result = await self.db.execute(stmt)
        title_suggestion = result.scalar_one_or_none()

        # Load SEO suggestions
        stmt = select(SEOSuggestion).where(SEOSuggestion.article_id == article_id)
        result = await self.db.execute(stmt)
        seo_suggestion = result.scalar_one_or_none()

        # Load FAQs
        stmt = select(ArticleFAQ).where(ArticleFAQ.article_id == article_id).order_by(ArticleFAQ.position)
        result = await self.db.execute(stmt)
        faqs = result.scalars().all()

        return {
            "title_suggestions": {
                "suggested_title_sets": title_suggestion.suggested_title_sets if title_suggestion else [],
                "optimization_notes": title_suggestion.optimization_notes if title_suggestion else [],
                "seo_title_suggestions": title_suggestion.suggested_seo_titles if title_suggestion else {},
            },
            "seo_suggestions": {
                "seo_keywords": {
                    "focus_keyword": seo_suggestion.focus_keyword if seo_suggestion else None,
                    "focus_keyword_rationale": seo_suggestion.focus_keyword_rationale if seo_suggestion else None,
                    "primary_keywords": seo_suggestion.primary_keywords if seo_suggestion else [],
                    "secondary_keywords": seo_suggestion.secondary_keywords if seo_suggestion else [],
                },
                "meta_description": {
                    "suggested_meta_description": seo_suggestion.suggested_meta_description if seo_suggestion else None,
                    "meta_description_improvements": seo_suggestion.meta_description_improvements if seo_suggestion else [],
                    "meta_description_score": seo_suggestion.meta_description_score if seo_suggestion else None,
                },
                "tags": {
                    "suggested_tags": seo_suggestion.suggested_tags if seo_suggestion else [],
                    "tag_strategy": seo_suggestion.tag_strategy if seo_suggestion else None,
                },
            },
            "faq_assessment": article.faq_assessment if article else {},
            "faq_applicable": article.faq_applicable if article else None,
            "faq_editorial_notes": article.faq_editorial_notes if article else {},
            "faq_html": article.faq_html if article else None,
            "faqs": [
                {
                    "question": faq.question,
                    "answer": faq.answer,
                    "question_type": faq.question_type,  # Already a string
                    "search_intent": faq.search_intent,  # Already a string
                    "keywords_covered": faq.keywords_covered or [],
                    "confidence": float(faq.confidence) if faq.confidence else None,
                    "safety_warning": faq.safety_warning,  # v2.2 YMYL
                }
                for faq in faqs
            ],
            "generation_metadata": {
                "cached": True,
                "message": "Loaded from cache (no AI call)",
            },
        }

    def _calculate_savings(self, cost_usd: float, total_tokens: int, duration_ms: int) -> dict:
        """Calculate savings vs separate API calls."""
        # Estimated cost/time for separate calls (original approach)
        # Step 1 Title: ~2,700 tokens, $0.02-0.03, 10-15s
        # Step 3 SEO+FAQ: ~5,500 tokens, $0.08-0.10, 20-25s
        original_tokens = 8200
        original_cost = 0.115  # Average of $0.10-0.13
        original_duration_ms = 35000  # Average of 30-40s

        saved_tokens = original_tokens - total_tokens
        saved_cost = original_cost - cost_usd
        saved_time_ms = original_duration_ms - duration_ms

        return {
            "original_tokens": original_tokens,
            "original_cost_usd": round(original_cost, 4),
            "original_duration_ms": original_duration_ms,
            "saved_tokens": saved_tokens,
            "saved_cost_usd": round(saved_cost, 4),
            "saved_duration_ms": saved_time_ms,
            "cost_savings_percentage": round((saved_cost / original_cost) * 100, 1),
            "time_savings_percentage": round((saved_time_ms / original_duration_ms) * 100, 1),
        }
