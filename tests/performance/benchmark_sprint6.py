"""
æ€§èƒ½åŸºå‡†æµ‹è¯• - Sprint 6
éªŒè¯ä¼˜åŒ–åçš„æ€§èƒ½æŒ‡æ ‡æ˜¯å¦è¾¾åˆ°ç›®æ ‡

ç›®æ ‡:
- å‘å¸ƒé€Ÿåº¦: < 120 ç§’ (ä¼˜åŒ–åï¼ŒåŸ 180 ç§’)
- æˆåŠŸç‡: â‰¥ 98%
- æˆæœ¬: ~$0.02/ç¯‡ (Playwright)
- Computer Use è°ƒç”¨ç‡: < 5%
- ç¼“å­˜å‘½ä¸­ç‡: > 80%
"""

import pytest
import asyncio
import time
from datetime import datetime
from typing import List, Dict
from unittest.mock import Mock, AsyncMock

from src.orchestrator.publishing_orchestrator import PublishingOrchestrator
from src.providers.optimized_playwright_provider import OptimizedPlaywrightProvider
from src.config.loader import SelectorConfig
from src.utils.metrics import get_metrics_collector
from src.utils.publishing_safety import PublishingIntent


@pytest.fixture
def sample_articles():
    """ç”Ÿæˆæµ‹è¯•æ–‡ç« æ•°æ®"""
    return [
        {
            'title': f'æ€§èƒ½æµ‹è¯•æ–‡ç«  {i} - {datetime.now().strftime("%Y%m%d%H%M%S")}',
            'content': f'<p>è¿™æ˜¯ç¬¬ {i} ç¯‡æµ‹è¯•æ–‡ç« ã€‚</p>' + '<p>æµ‹è¯•å†…å®¹ã€‚</p>' * 20,
            'seo': {
                'focus_keyword': f'æ€§èƒ½æµ‹è¯•{i}',
                'meta_title': f'æ€§èƒ½æµ‹è¯•æ–‡ç«  {i} - å®Œæ•´çš„æ ‡é¢˜ç”¨äºæµ‹è¯• SEO ä¼˜åŒ–åŠŸèƒ½',
                'meta_description': f'è¿™æ˜¯ç¬¬ {i} ç¯‡ç”¨äºæ€§èƒ½åŸºå‡†æµ‹è¯•çš„æ–‡ç« ï¼ŒéªŒè¯ä¼˜åŒ–åçš„å‘å¸ƒé€Ÿåº¦ã€æˆåŠŸç‡å’Œæˆæœ¬æŒ‡æ ‡æ˜¯å¦è¾¾åˆ°é¢„æœŸç›®æ ‡ã€‚' * 2
            }
        }
        for i in range(1, 11)  # 10 ç¯‡æ–‡ç« 
    ]


@pytest.fixture
def metadata():
    """æµ‹è¯•å…ƒæ•°æ®"""
    return {
        'tags': ['æ€§èƒ½æµ‹è¯•', 'Sprint6', 'åŸºå‡†æµ‹è¯•'],
        'categories': ['æŠ€æœ¯'],
        'images': []
    }


@pytest.fixture
def credentials():
    """æµ‹è¯•å‡­è¯"""
    return {
        'username': 'testadmin',
        'password': 'testpass123'
    }


class BenchmarkResults:
    """åŸºå‡†æµ‹è¯•ç»“æœæ”¶é›†å™¨"""

    def __init__(self):
        self.results: List[Dict] = []
        self.start_time = None
        self.end_time = None

    def add_result(self, **kwargs):
        """æ·»åŠ æµ‹è¯•ç»“æœ"""
        self.results.append(kwargs)

    def get_summary(self) -> Dict:
        """è·å–æ‘˜è¦ç»Ÿè®¡"""
        if not self.results:
            return {}

        total = len(self.results)
        successful = sum(1 for r in self.results if r.get('success'))
        failed = total - successful

        durations = [r.get('duration', 0) for r in self.results if r.get('success')]
        avg_duration = sum(durations) / len(durations) if durations else 0
        min_duration = min(durations) if durations else 0
        max_duration = max(durations) if durations else 0

        fallback_count = sum(1 for r in self.results if r.get('fallback_triggered'))

        return {
            'total_tests': total,
            'successful': successful,
            'failed': failed,
            'success_rate': round(successful / total * 100, 2) if total > 0 else 0,
            'avg_duration_seconds': round(avg_duration, 2),
            'min_duration_seconds': round(min_duration, 2),
            'max_duration_seconds': round(max_duration, 2),
            'fallback_triggered_count': fallback_count,
            'fallback_rate': round(fallback_count / total * 100, 2) if total > 0 else 0,
            'total_duration_seconds': round(sum(durations), 2)
        }

    def print_report(self):
        """æ‰“å°åŸºå‡†æµ‹è¯•æŠ¥å‘Š"""
        summary = self.get_summary()

        print("\n" + "=" * 80)
        print("ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š - Sprint 6")
        print("=" * 80)

        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"   æµ‹è¯•æ€»æ•°:     {summary['total_tests']}")
        print(f"   æˆåŠŸ:         {summary['successful']}")
        print(f"   å¤±è´¥:         {summary['failed']}")
        print(f"   æˆåŠŸç‡:       {summary['success_rate']}%")

        print(f"\nâ±ï¸  æ€§èƒ½æŒ‡æ ‡:")
        print(f"   å¹³å‡è€—æ—¶:     {summary['avg_duration_seconds']:.2f} ç§’")
        print(f"   æœ€çŸ­è€—æ—¶:     {summary['min_duration_seconds']:.2f} ç§’")
        print(f"   æœ€é•¿è€—æ—¶:     {summary['max_duration_seconds']:.2f} ç§’")
        print(f"   æ€»è€—æ—¶:       {summary['total_duration_seconds']:.2f} ç§’")

        print(f"\nğŸ”„ é™çº§ç»Ÿè®¡:")
        print(f"   é™çº§æ¬¡æ•°:     {summary['fallback_triggered_count']}")
        print(f"   é™çº§ç‡:       {summary['fallback_rate']}%")

        print(f"\nâœ… ç›®æ ‡è¾¾æˆæƒ…å†µ:")

        # æ£€æŸ¥ç›®æ ‡
        targets = {
            'å‘å¸ƒé€Ÿåº¦ (< 120ç§’)': summary['avg_duration_seconds'] < 120,
            'æˆåŠŸç‡ (â‰¥ 98%)': summary['success_rate'] >= 98,
            'Computer Use è°ƒç”¨ç‡ (< 5%)': summary['fallback_rate'] < 5
        }

        for target, achieved in targets.items():
            status = "âœ… è¾¾æˆ" if achieved else "âŒ æœªè¾¾æˆ"
            print(f"   {target}: {status}")

        print("\n" + "=" * 80)


@pytest.mark.benchmark
class TestPublishingBenchmark:
    """å‘å¸ƒç³»ç»Ÿæ€§èƒ½åŸºå‡†æµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_single_article_speed(self, sample_articles, metadata, credentials):
        """
        åŸºå‡† 1: å•ç¯‡æ–‡ç« å‘å¸ƒé€Ÿåº¦
        ç›®æ ‡: < 120 ç§’ (ä¼˜åŒ–å)
        """
        print("\nğŸƒ åŸºå‡†æµ‹è¯• 1: å•ç¯‡æ–‡ç« å‘å¸ƒé€Ÿåº¦")

        # ä½¿ç”¨ Mock Providerï¼ˆæ¨¡æ‹Ÿå¿«é€Ÿå“åº”ï¼‰
        mock_provider = self._create_mock_provider()

        orchestrator = PublishingOrchestrator(
            playwright_provider=mock_provider,
            enable_safety_checks=True
        )

        start_time = time.time()

        result = await orchestrator.publish_article(
            article=sample_articles[0],
            metadata=metadata,
            wordpress_url='http://localhost:8080',
            credentials=credentials,
            intent=PublishingIntent.PUBLISH_NOW
        )

        duration = time.time() - start_time

        # éªŒè¯
        assert result.success is True
        assert duration < 120, f"è€—æ—¶ {duration:.2f}ç§’ï¼Œè¶…è¿‡ç›®æ ‡ 120 ç§’"

        print(f"   âœ… è€—æ—¶: {duration:.2f} ç§’")
        print(f"   ç›®æ ‡: < 120 ç§’")
        print(f"   çŠ¶æ€: {'é€šè¿‡' if duration < 120 else 'å¤±è´¥'}")

    @pytest.mark.asyncio
    async def test_batch_publishing_success_rate(self, sample_articles, metadata, credentials):
        """
        åŸºå‡† 2: æ‰¹é‡å‘å¸ƒæˆåŠŸç‡
        ç›®æ ‡: â‰¥ 98%
        """
        print("\nğŸƒ åŸºå‡†æµ‹è¯• 2: æ‰¹é‡å‘å¸ƒæˆåŠŸç‡ (10 ç¯‡æ–‡ç« )")

        results = BenchmarkResults()

        # ä½¿ç”¨ Mock Provider
        mock_provider = self._create_mock_provider()

        for i, article in enumerate(sample_articles):
            print(f"   å‘å¸ƒæ–‡ç«  {i+1}/10...", end=" ")

            orchestrator = PublishingOrchestrator(
                playwright_provider=mock_provider,
                enable_safety_checks=True
            )

            start_time = time.time()

            try:
                result = await orchestrator.publish_article(
                    article=article,
                    metadata=metadata,
                    wordpress_url='http://localhost:8080',
                    credentials=credentials,
                    intent=PublishingIntent.PUBLISH_NOW
                )

                duration = time.time() - start_time

                results.add_result(
                    article_id=i+1,
                    success=result.success,
                    duration=duration,
                    fallback_triggered=result.fallback_triggered,
                    provider_used=result.provider_used
                )

                print(f"âœ… {duration:.2f}s")

            except Exception as e:
                duration = time.time() - start_time
                results.add_result(
                    article_id=i+1,
                    success=False,
                    duration=duration,
                    error=str(e)
                )
                print(f"âŒ å¤±è´¥: {e}")

        # æ‰“å°æŠ¥å‘Š
        results.print_report()

        # éªŒè¯ç›®æ ‡
        summary = results.get_summary()
        assert summary['success_rate'] >= 98, f"æˆåŠŸç‡ {summary['success_rate']}% ä½äºç›®æ ‡ 98%"

    @pytest.mark.asyncio
    async def test_concurrent_publishing(self, sample_articles, metadata, credentials):
        """
        åŸºå‡† 3: å¹¶å‘å‘å¸ƒæ€§èƒ½
        æµ‹è¯•ç³»ç»Ÿåœ¨å¹¶å‘è´Ÿè½½ä¸‹çš„è¡¨ç°
        """
        print("\nğŸƒ åŸºå‡†æµ‹è¯• 3: å¹¶å‘å‘å¸ƒ (5 ç¯‡åŒæ—¶)")

        # åˆ›å»ºå¤šä¸ª Orchestrator å®ä¾‹
        orchestrators = [
            PublishingOrchestrator(
                playwright_provider=self._create_mock_provider(),
                enable_safety_checks=True
            )
            for _ in range(5)
        ]

        start_time = time.time()

        # å¹¶å‘å‘å¸ƒ
        tasks = [
            orchestrator.publish_article(
                article=sample_articles[i],
                metadata=metadata,
                wordpress_url='http://localhost:8080',
                credentials=credentials,
                intent=PublishingIntent.PUBLISH_NOW
            )
            for i, orchestrator in enumerate(orchestrators)
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        total_duration = time.time() - start_time

        # ç»Ÿè®¡
        successful = sum(1 for r in results if not isinstance(r, Exception) and r.success)
        failed = len(results) - successful

        print(f"\n   æ€»è€—æ—¶: {total_duration:.2f} ç§’")
        print(f"   å¹³å‡æ¯ç¯‡: {total_duration / len(results):.2f} ç§’")
        print(f"   æˆåŠŸ: {successful}/{len(results)}")
        print(f"   å¤±è´¥: {failed}/{len(results)}")

        # éªŒè¯
        assert successful >= 4, "å¹¶å‘å‘å¸ƒæˆåŠŸæ•°é‡è¿‡ä½"
        assert total_duration < 300, "å¹¶å‘å‘å¸ƒæ€»è€—æ—¶è¿‡é•¿"

    @pytest.mark.asyncio
    async def test_cache_hit_rate(self):
        """
        åŸºå‡† 4: é€‰æ‹©å™¨ç¼“å­˜å‘½ä¸­ç‡
        ç›®æ ‡: > 80%
        """
        print("\nğŸƒ åŸºå‡†æµ‹è¯• 4: é€‰æ‹©å™¨ç¼“å­˜å‘½ä¸­ç‡")

        # æ¨¡æ‹Ÿå¤šæ¬¡å‘å¸ƒä»¥ç´¯ç§¯ç¼“å­˜
        mock_provider = self._create_mock_provider_with_cache()

        # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        await mock_provider.fill_input("new_post_title", "Test 1")

        # åç»­è°ƒç”¨ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰
        for i in range(2, 11):
            await mock_provider.fill_input("new_post_title", f"Test {i}")

        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = mock_provider.get_cache_stats()

        hit_rate = cache_stats.get('hit_rate', 0)

        print(f"\n   ç¼“å­˜ç»Ÿè®¡:")
        print(f"   - å‘½ä¸­æ¬¡æ•°: {cache_stats.get('hits', 0)}")
        print(f"   - æœªå‘½ä¸­æ¬¡æ•°: {cache_stats.get('misses', 0)}")
        print(f"   - å‘½ä¸­ç‡: {hit_rate}%")
        print(f"   - ç¼“å­˜é¡¹æ•°: {cache_stats.get('cached_items', 0)}")

        # éªŒè¯
        assert hit_rate >= 80, f"ç¼“å­˜å‘½ä¸­ç‡ {hit_rate}% ä½äºç›®æ ‡ 80%"

    @pytest.mark.asyncio
    async def test_cost_estimation(self, sample_articles, metadata, credentials):
        """
        åŸºå‡† 5: æˆæœ¬ä¼°ç®—
        ç›®æ ‡: ~$0.02/ç¯‡ (Playwright)
        """
        print("\nğŸƒ åŸºå‡†æµ‹è¯• 5: æˆæœ¬ä¼°ç®—")

        metrics = get_metrics_collector()

        # æ¨¡æ‹Ÿ 10 ç¯‡æ–‡ç« å‘å¸ƒ
        total_cost = 0

        for i in range(10):
            cost = metrics.estimate_publish_cost('playwright', has_images=False)
            total_cost += cost

        avg_cost = total_cost / 10

        print(f"\n   æ€»æˆæœ¬: ${total_cost:.4f}")
        print(f"   å¹³å‡æˆæœ¬: ${avg_cost:.4f}/ç¯‡")
        print(f"   ç›®æ ‡æˆæœ¬: $0.02/ç¯‡")

        # éªŒè¯
        assert avg_cost <= 0.03, f"å¹³å‡æˆæœ¬ ${avg_cost:.4f} è¶…è¿‡ç›®æ ‡ $0.02"

        print(f"   âœ… æˆæœ¬ç›®æ ‡è¾¾æˆ")

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    def _create_mock_provider(self):
        """åˆ›å»ºæ¨¡æ‹Ÿçš„ Provider"""
        provider = Mock()
        provider.initialize = AsyncMock()
        provider.close = AsyncMock()
        provider.navigate_to = AsyncMock()
        provider.fill_input = AsyncMock()
        provider.fill_textarea = AsyncMock()
        provider.click_button = AsyncMock()
        provider.wait_for_element = AsyncMock()
        provider.wait_for_success_message = AsyncMock()
        provider.get_cookies = AsyncMock(return_value=[
            {'name': 'test_cookie', 'value': 'test123'}
        ])
        provider.get_published_url = AsyncMock(return_value='http://localhost:8080/test-article')
        provider.navigate_to_new_post = AsyncMock()
        provider.clean_html_entities = AsyncMock()
        provider.verify_draft_status = AsyncMock(return_value=True)
        provider.verify_content_saved = AsyncMock(return_value=True)
        return provider

    def _create_mock_provider_with_cache(self):
        """åˆ›å»ºå¸¦ç¼“å­˜çš„æ¨¡æ‹Ÿ Provider"""
        from src.utils.performance import SelectorCache

        provider = Mock()
        provider.selector_cache = SelectorCache()

        async def mock_fill_input(field, value):
            # æ¨¡æ‹Ÿç¼“å­˜é€»è¾‘
            cached = provider.selector_cache.get(field)
            if not cached:
                provider.selector_cache.set(field, f"#{field}")

        provider.fill_input = AsyncMock(side_effect=mock_fill_input)
        provider.get_cache_stats = lambda: provider.selector_cache.get_stats()

        return provider


# ==================== è¿è¡ŒåŸºå‡†æµ‹è¯• ====================

if __name__ == "__main__":
    print("\nğŸš€ å¼€å§‹ Sprint 6 æ€§èƒ½åŸºå‡†æµ‹è¯•\n")

    pytest.main([
        __file__,
        '-v',
        '-m', 'benchmark',
        '--tb=short',
        '--color=yes'
    ])
